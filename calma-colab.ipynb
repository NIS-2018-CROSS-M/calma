{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCeEHECQvg1E",
    "colab_type": "text"
   },
   "source": [
    "# Run calma project with colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqmmFnqxvyz8",
    "colab_type": "text"
   },
   "source": [
    "meant to be ran on python3 [colab](https://colab.research.google.com) notebook with GPU. Go to Edit -> Notebook Settings to enable GPU in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMX1ayVmvFJ8",
    "colab_type": "text"
   },
   "source": [
    "## prepare colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vp1T6xL-qlkD",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# clone openmt-py used in calma and move it into the proper folder\n",
    "!git clone https://github.com/OpenNMT/OpenNMT-py.git\n",
    "!mv OpenNMT-py ~\n",
    "\n",
    "# clone and run a tool installing pytorch 0.4.1 with cuda 9.2 into colab (maybe works on any ubuntu 16)\n",
    "!git clone https://gist.github.com/f7b7c7758a46da49f84bc68b47997d69.git colab_cuda_upgrader\n",
    "!bash colab_cuda_upgrader/pytorch041_cuda92_colab.sh\n",
    "\n",
    "# install dependencies used in calma project\n",
    "!pip install torchtext configargparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRhR4Ht7vRc1",
    "colab_type": "text"
   },
   "source": [
    "## run ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "QLrE5m_qszdO",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# clone the calma project\n",
    "!git clone https://github.com/NIS-2018-CROSS-M/calma.git --branch data-adoptation --single-branch\n",
    "!make all -C calma"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "calma-colab.ipynb",
   "version": "0.3.2",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
